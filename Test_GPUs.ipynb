{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186df1f1-4728-4746-b112-db8270dc9e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n",
      "CUDA version: 12.1\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Number of CUDA cores: 20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "print(\"Number of CUDA cores:\", torch.cuda.get_device_properties(0).multi_processor_count if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cf34bda-8a00-4e9c-a4a1-ba430409e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.5550 seconds\n",
      "GPU time: 0.6867 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Tensor size for testing\n",
    "size = 5000\n",
    "\n",
    "# CPU Test\n",
    "a_cpu = torch.rand(size, size)\n",
    "b_cpu = torch.rand(size, size)\n",
    "\n",
    "start = time.time()\n",
    "c_cpu = torch.matmul(a_cpu, b_cpu)\n",
    "end = time.time()\n",
    "print(f\"CPU time: {end - start:.4f} seconds\")\n",
    "\n",
    "# GPU Test\n",
    "if torch.cuda.is_available():\n",
    "    a_gpu = a_cpu.to('cuda')\n",
    "    b_gpu = b_cpu.to('cuda')\n",
    "    \n",
    "    torch.cuda.synchronize()  # Make sure GPU is ready\n",
    "    start = time.time()\n",
    "    c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()  # Wait for completion\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"GPU time: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff179ce7-4b3e-4835-b974-c8a8a03e1e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU memory (GB): 6.44\n",
      "Current allocated memory (MB): 310.51\n",
      "Current cached memory (MB): 322.96\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_properties = torch.cuda.get_device_properties(0)\n",
    "    print(\"Total GPU memory (GB):\", round(gpu_properties.total_memory / 1e9, 2))\n",
    "    print(\"Current allocated memory (MB):\", round(torch.cuda.memory_allocated(0)/1e6, 2))\n",
    "    print(\"Current cached memory (MB):\", round(torch.cuda.memory_reserved(0)/1e6, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a761b0b-8659-4014-94d2-a56044620c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training step time: 5.7226 seconds\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "data = torch.randn(64, 3, 224, 224).to(device)  # batch size 64\n",
    "labels = torch.randint(0, 1000, (64,)).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Timing one forward + backward pass\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "outputs = model(data)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "print(f\"One training step time: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2be8893-91e4-462f-a164-75a4c2388d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU run 1: 0.5321 s\n",
      "GPU run 2: 0.5317 s\n",
      "GPU run 3: 0.5324 s\n",
      "GPU run 4: 0.5308 s\n",
      "GPU run 5: 0.5309 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print(f\"GPU run {i+1}: {end - start:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a0d467-55e0-4094-b687-9b43d2e0d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training step time: 3.3249 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch, time\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = models.resnet18().to(device)\n",
    "data = torch.randn(64,3,224,224).to(device)\n",
    "labels = torch.randint(0,1000,(64,)).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(5):\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# Actual benchmark\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Average training step time: {(end-start)/10:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36acd71d-fa1e-418a-92b2-9fdb0d6261ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "CPU matrix multiplication: 12.6980 s\n",
      "GPU matrix multiplication (avg of 5 runs): 5.0898 s\n",
      "Average training step time on GPU: 3.3299 s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "# ✅ Choose device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n",
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ Matrix Multiplication Test\n",
    "# ------------------------------\n",
    "size = 10000  # large enough for GPU to shine\n",
    "a_cpu = torch.rand(size, size)\n",
    "b_cpu = torch.rand(size, size)\n",
    "\n",
    "# CPU\n",
    "start = time.time()\n",
    "c_cpu = torch.matmul(a_cpu, b_cpu)\n",
    "end = time.time()\n",
    "print(f\"CPU matrix multiplication: {end-start:.4f} s\")\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    a_gpu = a_cpu.to('cuda')\n",
    "    b_gpu = b_cpu.to('cuda')\n",
    "    \n",
    "    # Warm-up GPU (important!)\n",
    "    for _ in range(3):\n",
    "        torch.matmul(a_gpu, b_gpu)\n",
    "    \n",
    "    # Timed GPU\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(5):\n",
    "        c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    print(f\"GPU matrix multiplication (avg of 5 runs): {(end-start)/5:.4f} s\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2️⃣ Mini Training Step Test\n",
    "# ------------------------------\n",
    "batch_size = 64\n",
    "model = models.resnet18().to(device)\n",
    "data = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "labels = torch.randint(0, 1000, (batch_size,)).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Warm-up GPU\n",
    "for _ in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Timed training steps\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "steps = 10\n",
    "for _ in range(steps):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Average training step time on GPU: {(end-start)/steps:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49acbd-c506-495f-9d92-7563f61aac24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
